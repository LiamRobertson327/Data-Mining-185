{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# twitter_handle = []\n",
    "\n",
    "# for row in wiz_per_game.find_all('tr')[1:]:\n",
    "#     player = {}\n",
    "    \n",
    "#     # Taking the row's first hyperlink (player's url ending) and appending it to the base url \n",
    "#     # to get the player's personal webpage url. \n",
    "#     player_url = ('https://www.basketball-reference.com/' + row.find('a').attrs['href'])\n",
    "    \n",
    "#     # Making a new BeautifulSoup instance of the player's webpage and narrowing it to the top section\n",
    "#     player_rest = requests.get(player_url)\n",
    "#     player_soup = BeautifulSoup(player_rest.content, 'lxml')\n",
    "#     player_info = player_soup.find(name = 'div', attrs = {'id' : 'meta'})\n",
    "#     # Adding player's name for clarity\n",
    "#     player['Name'] = row.find('a').text.strip()\n",
    "    \n",
    "#     # Creating a list of all the hyperlinks from player_info\n",
    "#     player_links= []\n",
    "#     for link in player_info.find_all('a'):\n",
    "#         player_links.append(link.get('href'))\n",
    "    \n",
    "#     # If a player's twitter exists, the link is second in the player_links list. If it doesn't exist, \n",
    "#     # the value is set to 'Not Listed'.\n",
    "#     if 'twitter' in player_links[1]:\n",
    "#         player['Twitter Handle'] = player_links[1].replace('https://twitter.com/', '')\n",
    "#     else:\n",
    "#         player['Twitter Handle'] = 'Not Listed'\n",
    "        \n",
    "#     twitter_handle.append(player)\n",
    "    \n",
    "# pd.DataFrame(twitter_handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "# URL for the Washington Wizards Basketball Reference page\n",
    "wiz_url = (f'https://www.basketball-reference.com/teams/WAS/2021.html')\n",
    "ts = wiz_url\n",
    "ts = ts[43:-5]\n",
    "ts = ts.replace(\"/\",\"-\")\n",
    "\n",
    "# The requests library can send a GET request to the wiz_url\n",
    "wiz_res = requests.get(wiz_url)\n",
    "print(wiz_res)\n",
    "# BeautifulSoup library parses the content of an HTML document, in this case wiz_res\n",
    "wiz_soup = BeautifulSoup(wiz_res.content, 'lxml')\n",
    "\n",
    "# BeautifulSoup's .find() method searches for a tag and specified attributes, \n",
    "# returning the first match \n",
    "wiz_per_game = wiz_soup.find(name = 'table', attrs = {'id' : 'per_game'})\n",
    "\n",
    "# Making a list of dictionaries to then convert into a pd.DataFrame\n",
    "wiz_info = []\n",
    "for row in wiz_per_game.find_all('tr')[1:]:  # Excluding the first 'tr', since that's the table's title head\n",
    "    \n",
    "    player = {}\n",
    "    player['Player'] = row.find('a').text.strip()\n",
    "    player['Age'] = row.find('td', {'data-stat' : 'age'}).text\n",
    "\n",
    "    player['DWS'] = row.find('td', {'data-stat' : 'drb_per_g'}).text\n",
    "    player['OWS'] = row.find('td', {'data-stat' : 'orb_per_g'}).text\n",
    "\n",
    "    player['PTS'] = row.find('td', {'data-stat' : 'pts_per_g'}).text\n",
    "\n",
    "    player_url = ('https://www.basketball-reference.com/' + row.find('a').attrs['href'])\n",
    "    time.sleep(2)\n",
    "    player_rest = requests.get(player_url)\n",
    "    player_soup = BeautifulSoup(player_rest.content, 'lxml')\n",
    "    player_info = player_soup.find(name = 'div', attrs = {'id' : 'meta'})\n",
    "    player_links= []\n",
    "    for link in player_info.find_all('a'):\n",
    "        player_links.append(link.get('href'))\n",
    "\n",
    "    if 'twitter' in player_links[1]:\n",
    "        player['Twitter Handle'] = player_links[1].replace('https://twitter.com/', '')\n",
    "    else:\n",
    "        player['Twitter Handle'] = 'Not Listed'\n",
    "\n",
    "    s = str(player_info.find_all('p'))\n",
    "    # with open(\"html_files/sinfo.html\", \"w\") as file:\n",
    "    #     file.write(s)\n",
    "    # Find the p tag that contains the height and weight\n",
    "\n",
    "    # Open the file and read the HTML content\n",
    "    with open(\"html_files/sinfo.html\", \"r\") as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    \n",
    "    # Use a regular expression to find the height and weight\n",
    "    height_weight_match = re.search(r'\\((\\d+cm),\\s*(\\d+kg)\\)', s)\n",
    "    \n",
    "    # Check if the height and weight were found\n",
    "    if height_weight_match:\n",
    "        height, weight = height_weight_match.groups()\n",
    "    else:\n",
    "        print(\"The height and weight information could not be found.\")\n",
    "    player['Height'] = height.rstrip('cm')\n",
    "    player['Weight (Lbs)'] = weight.rstrip('kg')\n",
    "    # player['Position'] = position.group(1).strip()\n",
    "    \n",
    "    wiz_info.append(player)\n",
    "\n",
    "temp = pd.DataFrame(wiz_info)\n",
    "temp.to_csv(f\"csv_files/{ts}-data_corr.csv\",header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.stats import linregress\n",
    "# import csv\n",
    "# from scipy.optimize import curve_fit\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# # Replace what is inside the quotes with wherever you placed the file\n",
    "# with open(f'csv_files/{ts}-wiz_stats.csv') as csvfile:\n",
    "#     readCSVplayer = csv.reader(csvfile, delimiter = ',')\n",
    "#     next(readCSVplayer)\n",
    "#     player = []\n",
    "#     age = []\n",
    "#     DWS = []\n",
    "#     OWS = []\n",
    "#     PTS = []\n",
    " \n",
    "#     for row in readCSVplayer:\n",
    "#         currPlayer = row[0]\n",
    "#         currAge = row[1]\n",
    "#         currDWS = row[2]\n",
    "#         currOWS = row[3]\n",
    "#         currPTS=row[4]\n",
    "\n",
    "#         player.append(currPlayer)\n",
    "#         age.append(currAge)\n",
    "#         DWS.append(currDWS)\n",
    "#         OWS.append(currOWS)\n",
    "#         PTS.append(currPTS)\n",
    "        \n",
    "# floatAge = [float(i) for i in age]\n",
    "# floatDWS = [float(i) for i in DWS]\n",
    "# floatOWS = [float(i) for i in OWS]\n",
    "# floatPTS = [float(i) for i in PTS]\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    " \n",
    "# agePlotPTS, ax = plt.subplots()\n",
    "# DWSPlotPTS, ax2 = plt.subplots()\n",
    "# OWSPlotPTS, ax3 = plt.subplots()\n",
    "\n",
    "# #Ax is between age and PTS. \n",
    "# ax.scatter(floatAge, floatPTS, label = \"All active NBA players\", color = 'purple')\n",
    "# ax.axvline(x = np.mean(floatAge), color = 'grey') #X-axis\n",
    "# ax.axhline(y = np.mean(floatPTS), label = \"Average\", color = 'grey') #Y-axis\n",
    "# agePlotPTS.suptitle(\"Correlation between age and PTS\", weight = 'bold', size = 18, y = 1.05)\n",
    "# ax.set_title(\"Linear Trendline.\", size = 12, fontname = 'Rockwell')\n",
    "# ax.set_xlabel(\"Age(years))\")\n",
    "# ax.set_ylabel(\"Points(PTS)\")\n",
    "\n",
    "# ax.plot(np.unique(floatAge), np.poly1d(np.polyfit(floatAge, floatPTS, 1))(np.unique(floatAge)), 'blue')\n",
    " \n",
    "# ax.legend(loc='best', prop={'size': 9, \"family\": \"Rockwell\"})\n",
    "\n",
    "# print(\"***************\\n\")\n",
    "# slope, intercept, r_value, p_value, std_err = linregress(floatAge, floatPTS)\n",
    "# print(\"Age and PTS: slope =\", slope, \", intercept =\", intercept, \", r_value =\", r_value,\n",
    "#     \", p_value =\", p_value, \", std_err =\", std_err)\n",
    "# rpString = \"r = \" + str(round(r_value, 3)) + \", p = \" + str(round(p_value, 7))\n",
    "# print(\"***************\\n\")\n",
    " \n",
    "# # Ax2 is between DWS and PTS.\n",
    "# ax2.scatter(floatDWS, floatPTS, label = \"All active NBA players\", color = 'purple')\n",
    "# ax2.axvline(x = np.mean(floatDWS), color = 'grey')\n",
    "# ax2.axhline(y = np.mean(floatPTS), label = \"Average\", color = 'grey')\n",
    "# DWSPlotPTS.suptitle(\"Correlation between DWS and PTS\", weight = 'bold', size = 18, y = 1.05)\n",
    "# ax2.set_title(\"Linear Trendline.\", size = 12, fontname = 'Rockwell')\n",
    "# ax2.set_xlabel(\"DWS\")\n",
    "# ax2.set_ylabel(\"Points(PTS)\") \n",
    "\n",
    "# ax2.plot(np.unique(floatDWS), np.poly1d(np.polyfit(floatDWS, floatPTS, 1))(np.unique(floatDWS)), 'blue')\n",
    " \n",
    "# ax2.legend(loc='best', prop={'size': 9, 'family': 'Rockwell'})\n",
    "# print(\"***************\\n\")\n",
    "# slope, intercept, r_value, p_value, std_err = linregress(floatDWS, floatPTS)\n",
    "# print(\"DWS and PTS: slope =\", slope, \", intercept =\", intercept, \", r_value =\", r_value,\n",
    "#     \", p_value =\", p_value, \", std_err =\", std_err)\n",
    "# rpString = \"r = \" + str(round(r_value, 3)) + \", p = \" + str(round(p_value, 3))\n",
    "# print(\"***************\\n\")\n",
    "\n",
    "# # Ax2 is between OWS and PTS.\n",
    "# ax3.scatter(floatOWS, floatPTS, label = \"All active NBA players\", color = 'purple')\n",
    "# ax3.axvline(x = np.mean(floatOWS), color = 'grey')\n",
    "# ax3.axhline(y = np.mean(floatPTS), label = \"Average\", color = 'grey')\n",
    "# OWSPlotPTS.suptitle(\"Correlation between OWS and PTS\", weight = 'bold', size = 18, y = 1.05)\n",
    "# ax3.set_title(\"Linear Trendline.\", size = 12, fontname = 'Rockwell')\n",
    "# ax3.set_xlabel(\"OWS\")\n",
    "# ax3.set_ylabel(\"Points(PTS)\") \n",
    "\n",
    "# ax3.plot(np.unique(floatOWS), np.poly1d(np.polyfit(floatOWS, floatPTS, 1))(np.unique(floatOWS)), 'blue')\n",
    " \n",
    "# ax3.legend(loc='best', prop={'size': 9, 'family': 'Rockwell'})\n",
    "# print(\"***************\\n\")\n",
    "# slope, intercept, r_value, p_value, std_err = linregress(floatOWS, floatPTS)\n",
    "# print(\"OWS and PTS: slope =\", slope, \", intercept =\", intercept, \", r_value =\", r_value,\n",
    "#     \", p_value =\", p_value, \", std_err =\", std_err)\n",
    "# rpString = \"r = \" + str(round(r_value, 3)) + \", p = \" + str(round(p_value, 3))\n",
    "# print(\"***************\\n\")\n",
    " \n",
    "\n",
    "# # Remove if you do not want to save the figures in your working directory\n",
    "# # Change the DPI to adjust image size\n",
    "# agePlotPTS.savefig(f'Photos/{ts}-age-PTS-linear.png', dpi = 400, bbox_inches = 'tight')\n",
    "# DWSPlotPTS.savefig(f'Photos/{ts}-DWS-PTS-linear.png', dpi = 400, bbox_inches = 'tight')\n",
    "# OWSPlotPTS.savefig(f'Photos/{ts}-OWS-PTS-linear.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of PTS and Weight (Lbs):            0.0710455804049308\n",
      "\n",
      "Correlation of PTS and Height:            -0.13457938919958876\n",
      "\n",
      "Correlation of Weight (Lbs) and Height:            0.8375470365702434\n",
      "\n",
      "Correlation of PTS and Age:            0.32095713341753346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculating correlations with the wiz_stats data\n",
    "\n",
    "import pandas as pd\n",
    "player_data = pd.read_csv(f\"csv_files/{ts}-data_corr.csv\")\n",
    "player_data_cleaned = player_data[[\"PTS\",\"Weight (Lbs)\",\"Height\",\"Age\"]]\n",
    "data = []\n",
    "Output = open(f\"Text/{ts}-Correleations.txt\",\"w\")\n",
    "\n",
    "for i in range (len(player_data_cleaned.columns)):\n",
    "    data.append(player_data_cleaned[player_data_cleaned.columns[i]])\n",
    "\n",
    "for i in range(0,len(data)-2):\n",
    "    for j in range(i+1,len(data)-1):\n",
    "        correlation = data[i].corr(data[j]) #Calculate correlation coefficient\n",
    "        Output.write(f\"Correlation of {player_data_cleaned.columns[i]} and {player_data_cleaned.columns[j]}: {\"\":10} {correlation}\\n\")\n",
    "        print(f\"Correlation of {player_data_cleaned.columns[i]} and {player_data_cleaned.columns[j]}: {\"\":10} {correlation}\\n\")\n",
    "\n",
    "correlation = data[0].corr(data[3]) #Calculate correlation coefficient\n",
    "Output.write(f\"Correlation of {player_data_cleaned.columns[0]} and {player_data_cleaned.columns[3]}: {\"\":10} {correlation}\\n\")\n",
    "print(f\"Correlation of {player_data_cleaned.columns[0]} and {player_data_cleaned.columns[3]}: {\"\":10} {correlation}\\n\")\n",
    "\n",
    "Output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
